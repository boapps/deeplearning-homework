{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naang\\anaconda3\\envs\\DL_test\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\naang\\anaconda3\\envs\\DL_test\\lib\\site-packages\\huggingface_hub\\file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.1.proj.weight', 'decode_head.batch_norm.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.batch_norm.running_var', 'decode_head.classifier.bias', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.running_mean']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\naang\\anaconda3\\envs\\DL_test\\lib\\site-packages\\transformers\\models\\segformer\\image_processing_segformer.py:99: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoModelForSemanticSegmentation, AutoImageProcessor\n",
    "import numpy as np\n",
    "\n",
    "checkpoint = \"nvidia/mit-b0\"\n",
    "id2label = {i: str(i) for i in range(20)}\n",
    "id2label[255] = \"255\"\n",
    "label2id = {str(i): i for i in range(20)}\n",
    "label2id[\"255\"] = 255\n",
    "\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "\n",
    "def model_a(image):\n",
    "    inputs = image_processor(images=[image], return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        upsampled_logits = torch.nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=image.size[::-1],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        predicted_segmentation = upsampled_logits.argmax(dim=1).squeeze().cpu().numpy()\n",
    "    return Image.fromarray((predicted_segmentation * 255).astype(np.uint8))\n",
    "\n",
    "def model_b(image):\n",
    "    return image\n",
    "\n",
    "def model_c(image):\n",
    "    return image\n",
    "\n",
    "def segment_image(image, model_choice):\n",
    "    if model_choice == \"Model A\":\n",
    "        return model_a(image)\n",
    "    elif model_choice == \"Model B\":\n",
    "        return model_b(image)\n",
    "    elif model_choice == \"Model C\":\n",
    "        return model_c(image)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=segment_image,\n",
    "    inputs=[gr.Image(type=\"pil\"), gr.Dropdown(choices=[\"Model A\", \"Model B\", \"Model C\"], label=\"Select Model\")],\n",
    "    outputs=gr.Image(type=\"pil\")\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
